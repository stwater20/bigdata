{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   New_ID  Old_ID Train_Test  \\\n",
      "0       1    5544      TRAIN   \n",
      "1       2    5545      TRAIN   \n",
      "2       3    5546      TRAIN   \n",
      "3       4    5547      TRAIN   \n",
      "4       5    5548      TRAIN   \n",
      "\n",
      "                                              Title  \\\n",
      "0                                BAHIA COCOA REVIEW   \n",
      "1         STANDARD OIL <SRD> TO FORM FINANCIAL UNIT   \n",
      "2        TEXAS COMMERCE BANCSHARES <TCB> FILES PLAN   \n",
      "3      TALKING POINT/BANKAMERICA <BAC> EQUITY OFFER   \n",
      "4  NATIONAL AVERAGE PRICES FOR FARMER-OWNED RESERVE   \n",
      "\n",
      "                                                Body  \n",
      "0  Showers continued throughout the week in the B...  \n",
      "1  Standard Oil Co and BP North America Inc said ...  \n",
      "2  Texas Commerce Bancshares Inc's Texas Commerce...  \n",
      "3  BankAmerica Corp is not under pressure to act ...  \n",
      "4  The U.S. Agriculture Department reported the f...  \n",
      "Cleaned data saved to: cleaned_documents.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "csv_file_path = 'documents.csv'\n",
    "\n",
    "df = pd.read_csv(\n",
    "    csv_file_path,\n",
    "    quotechar='\"',  \n",
    "    escapechar='\\\\', \n",
    "    delimiter=',', \n",
    "    encoding='utf-8',  \n",
    "    engine='python' \n",
    ")\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):  \n",
    "        return \"\"\n",
    "    return text.replace('\u0003', '').strip()  \n",
    "\n",
    "\n",
    "df['Title'] = df['Title'].apply(clean_text)\n",
    "df['Body'] = df['Body'].apply(clean_text)\n",
    "\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "output_cleaned_csv = 'cleaned_documents.csv'\n",
    "df.to_csv(output_cleaned_csv, index=False, encoding='utf-8')\n",
    "\n",
    "\n",
    "print(f\"Cleaned data saved to: {output_cleaned_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-Shingle binary matrix has been saved to: shingle_binary_matrix.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "csv_file_path = 'cleaned_documents.csv'  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "\n",
    "def generate_shingles(text, k=3):\n",
    "    if pd.isna(text):  \n",
    "        return []\n",
    "\n",
    "    words = [word for word in text.split() if word.strip()]\n",
    "    # 生成3-shingles\n",
    "    shingles = [' '.join(words[i:i + k]) for i in range(len(words) - k + 1)]\n",
    "    return shingles\n",
    "\n",
    "df['Shingles'] = df['Body'].apply(generate_shingles)\n",
    "\n",
    "\n",
    "df['Shingle_Text'] = df['Shingles'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=lambda x: x.split(), binary=True)\n",
    "shingle_matrix = vectorizer.fit_transform(df['Shingle_Text'])\n",
    "\n",
    "\n",
    "shingle_matrix_df = pd.DataFrame(\n",
    "    shingle_matrix.T.toarray(),  \n",
    "    index=vectorizer.get_feature_names_out(),  \n",
    "    columns=df['New_ID'] \n",
    ")\n",
    "\n",
    "\n",
    "output_csv_path = 'shingle_binary_matrix.csv'  \n",
    "shingle_matrix_df.to_csv(output_csv_path)\n",
    "\n",
    "\n",
    "print(f\"3-Shingle binary matrix has been saved to: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinHash signature matrix has been saved to: minhash_signature_matrix.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "shingle_matrix_path = 'shingle_binary_matrix.csv'\n",
    "shingle_matrix_df = pd.read_csv(shingle_matrix_path, index_col=0)\n",
    "\n",
    "\n",
    "binary_matrix = shingle_matrix_df.to_numpy()\n",
    "\n",
    "\n",
    "H = 100  \n",
    "N = binary_matrix.shape[1]  \n",
    "\n",
    "\n",
    "minhash_matrix = np.full((H, N), np.inf)\n",
    "\n",
    "np.random.seed(42)  \n",
    "a = np.random.randint(1, 1e6, H)\n",
    "b = np.random.randint(0, 1e6, H)\n",
    "p = 2**31 - 1  \n",
    "num_shingles = binary_matrix.shape[0]\n",
    "\n",
    "\n",
    "def hash_func(x, a, b, p, num_shingles):\n",
    "    return ((a * x + b) % p) % num_shingles\n",
    "\n",
    "\n",
    "for row_id in range(num_shingles):\n",
    "    shingle_vector = binary_matrix[row_id, :]\n",
    "    hash_values = hash_func(row_id, a[:, None], b[:, None], p, num_shingles)\n",
    "    minhash_matrix[:, shingle_vector == 1] = np.minimum(\n",
    "        minhash_matrix[:, shingle_vector == 1], hash_values\n",
    "    )\n",
    "\n",
    "\n",
    "minhash_matrix_df = pd.DataFrame(minhash_matrix)\n",
    "output_minhash_path = 'minhash_signature_matrix.csv'\n",
    "minhash_matrix_df.to_csv(output_minhash_path, index=False)\n",
    "\n",
    "\n",
    "print(f\"MinHash signature matrix has been saved to: {output_minhash_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate pairs have been saved to: candidate_pairs.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "minhash_matrix_path = 'minhash_signature_matrix.csv'\n",
    "minhash_matrix = pd.read_csv(minhash_matrix_path).to_numpy()\n",
    "\n",
    "\n",
    "H, N = minhash_matrix.shape \n",
    "b = 20 \n",
    "r = H // b  \n",
    "\n",
    "assert H % b == 0, \"H 要被b整除\"\n",
    "\n",
    "\n",
    "candidate_pairs = set()\n",
    "\n",
    "\n",
    "for band in range(b):\n",
    "    start_row = band * r\n",
    "    end_row = start_row + r\n",
    "    band_matrix = minhash_matrix[start_row:end_row, :]\n",
    "\n",
    "\n",
    "    buckets = defaultdict(list)\n",
    "    \n",
    "\n",
    "    for doc_id in range(N):\n",
    "        band_signature = tuple(band_matrix[:, doc_id])\n",
    "        buckets[band_signature].append(doc_id)\n",
    "\n",
    "\n",
    "    for bucket in buckets.values():\n",
    "        if len(bucket) > 1:  \n",
    "            for i in range(len(bucket)):\n",
    "                for j in range(i + 1, len(bucket)):\n",
    "                    candidate_pairs.add((bucket[i], bucket[j]))\n",
    "\n",
    "\n",
    "candidate_pairs_df = pd.DataFrame(list(candidate_pairs), columns=[\"Document1\", \"Document2\"])\n",
    "\n",
    "\n",
    "candidate_pairs_path = 'candidate_pairs.csv'\n",
    "candidate_pairs_df.to_csv(candidate_pairs_path, index=False)\n",
    "\n",
    "print(f\"Candidate pairs have been saved to: {candidate_pairs_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
